{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87033b3b",
   "metadata": {},
   "source": [
    "# Data Quality & Validation\n",
    "\n",
    "This notebook demonstrates data quality checks, anomaly detection, and data cleaning workflows.\n",
    "\n",
    "**Topics**:\n",
    "1. Data completeness and missing values\n",
    "2. Kicking score anomalies\n",
    "3. Name matching and player identification\n",
    "4. Position consistency\n",
    "5. Temporal continuity checks\n",
    "6. Data cleaning report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rugby_ranking.notebook_utils import setup_notebook_environment\n",
    "from rugby_ranking.model.data import normalize_player_name\n",
    "from rugby_ranking.model.inference import MODEL_CONFIG\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Setup\n",
    "dataset, df, model_dir = setup_notebook_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e5879",
   "metadata": {},
   "source": [
    "## 1. Data Overview\n",
    "\n",
    "Basic statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nDate Range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Unique Teams: {df['team'].nunique()}\")\n",
    "print(f\"Unique Players: {df['player_name'].nunique()}\")\n",
    "print(f\"Unique Competitions: {df.get('competition', pd.Series()).nunique()}\")\n",
    "\n",
    "print(f\"\\nScore Distribution:\")\n",
    "print(df['score'].value_counts().sort_index().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81977778",
   "metadata": {},
   "source": [
    "## 2. Missing Values\n",
    "\n",
    "Check for missing data in key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "for col in df.columns:\n",
    "    if missing[col] > 0:\n",
    "        print(f\"  {col}: {missing[col]} ({missing_pct[col]:.2f}%)\")\n",
    "    \n",
    "if missing.sum() == 0:\n",
    "    print(\"  ✓ No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abbc94",
   "metadata": {},
   "source": [
    "## 3. Kicking Score Anomalies\n",
    "\n",
    "Identify unusual kicking patterns (e.g., kicker with 100+ points in a season)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7709fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to kickers (forwards don't kick)\n",
    "kicking_positions = MODEL_CONFIG['kicking_positions']\n",
    "kickers = df[df['position'].isin(kicking_positions)].copy()\n",
    "\n",
    "# Seasonal aggregation\n",
    "seasonal_kicking = kickers.groupby(['season', 'player_name', 'team']).agg({\n",
    "    'score': 'sum',\n",
    "    'date': 'count'  # number of matches\n",
    "}).rename(columns={'date': 'matches'})\n",
    "\n",
    "# Find anomalies\n",
    "anomalies = seasonal_kicking[seasonal_kicking['score'] > 100]\n",
    "\n",
    "print(f\"High kicking seasons (>100 points):\")\n",
    "if len(anomalies) > 0:\n",
    "    print(anomalies.sort_values('score', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"  None found\")\n",
    "\n",
    "# Average points per match\n",
    "seasonal_kicking['points_per_match'] = seasonal_kicking['score'] / seasonal_kicking['matches']\n",
    "high_avg = seasonal_kicking[seasonal_kicking['points_per_match'] > 5]\n",
    "\n",
    "print(f\"\\nHigh average kicking (>5 pts/match):\")\n",
    "if len(high_avg) > 0:\n",
    "    print(high_avg.sort_values('points_per_match', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"  None found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48518555",
   "metadata": {},
   "source": [
    "## 4. Name Normalization Issues\n",
    "\n",
    "Check for name variations that might represent the same player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find variations of player names (same team, similar names)\n",
    "def find_name_variations(df, team, max_variations=5):\n",
    "    team_players = df[df['team'] == team]['player_name'].unique()\n",
    "    \n",
    "    # Group by normalized name\n",
    "    normalized = {}\n",
    "    for name in team_players:\n",
    "        norm = normalize_player_name(name)\n",
    "        if norm not in normalized:\n",
    "            normalized[norm] = []\n",
    "        normalized[norm].append(name)\n",
    "    \n",
    "    # Find groups with multiple names\n",
    "    variations = {k: v for k, v in normalized.items() if len(v) > 1}\n",
    "    return variations\n",
    "\n",
    "# Sample teams\n",
    "teams_sample = df['team'].unique()[:5]\n",
    "print(f\"Checking {len(teams_sample)} teams for name variations:\")\n",
    "\n",
    "all_variations = {}\n",
    "for team in teams_sample:\n",
    "    vars = find_name_variations(df, team)\n",
    "    if vars:\n",
    "        all_variations[team] = vars\n",
    "\n",
    "if all_variations:\n",
    "    for team, vars in all_variations.items():\n",
    "        print(f\"\\n{team}:\")\n",
    "        for norm_name, names in list(vars.items())[:3]:\n",
    "            print(f\"  {norm_name}: {names}\")\n",
    "else:\n",
    "    print(\"\\n✓ No name variations detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed2aa4",
   "metadata": {},
   "source": [
    "## 5. Position Consistency\n",
    "\n",
    "Check whether players maintain consistent positions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40796cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each player, check position changes\n",
    "player_positions = df.groupby('player_name')['position'].nunique()\n",
    "\n",
    "position_changers = player_positions[player_positions > 1]\n",
    "print(f\"Players with position changes: {len(position_changers)} / {len(player_positions)} ({len(position_changers)/len(player_positions)*100:.1f}%)\")\n",
    "\n",
    "if len(position_changers) > 0:\n",
    "    print(f\"\\nTop position-changers:\")\n",
    "    for player in position_changers.nlargest(5).index:\n",
    "        positions = df[df['player_name'] == player]['position'].unique()\n",
    "        counts = df[df['player_name'] == player].groupby('position').size()\n",
    "        print(f\"  {player}: {dict(counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7569153",
   "metadata": {},
   "source": [
    "## 6. Temporal Continuity\n",
    "\n",
    "Check for gaps in match records and unusual patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a38f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match frequency by team\n",
    "matches_by_team = df.groupby('team').groupby(['date', 'team']).size().reset_index(name='players').groupby('team').size()\n",
    "\n",
    "print(f\"Matches per team (min, max, mean):\")\n",
    "print(f\"  Min: {matches_by_team.min()}\")\n",
    "print(f\"  Max: {matches_by_team.max()}\")\n",
    "print(f\"  Mean: {matches_by_team.mean():.1f}\")\n",
    "\n",
    "# Find teams with suspiciously few matches\n",
    "low_match_teams = matches_by_team[matches_by_team < matches_by_team.quantile(0.25)]\n",
    "if len(low_match_teams) > 0:\n",
    "    print(f\"\\n⚠️  Teams with low match counts:\")\n",
    "    for team, count in low_match_teams.items():\n",
    "        print(f\"  {team}: {count} matches\")\n",
    "else:\n",
    "    print(\"\\n✓ Match distribution looks reasonable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7268d",
   "metadata": {},
   "source": [
    "## 7. Data Cleaning Summary\n",
    "\n",
    "Generate a report of data quality issues and recommended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "issues = []\n",
    "recommendations = []\n",
    "\n",
    "# Check 1: Missing values\n",
    "missing_total = df.isnull().sum().sum()\n",
    "if missing_total > 0:\n",
    "    issues.append(f\"{missing_total} missing values across all columns\")\n",
    "    recommendations.append(\"Investigate and impute missing values\")\n",
    "else:\n",
    "    print(\"✓ No missing values\\n\")\n",
    "\n",
    "# Check 2: Name variations\n",
    "if len(all_variations) > 0:\n",
    "    issues.append(f\"Name variations found in {len(all_variations)} teams\")\n",
    "    recommendations.append(\"Standardize player names or merge duplicate records\")\n",
    "else:\n",
    "    print(\"✓ Name variations minimal\\n\")\n",
    "\n",
    "# Check 3: Position changes\n",
    "if len(position_changers) > 0:\n",
    "    issues.append(f\"{len(position_changers)} players changed positions\")\n",
    "    recommendations.append(\"Review position changes; consider position as time-varying\")\n",
    "else:\n",
    "    print(\"✓ Position consistency good\\n\")\n",
    "\n",
    "# Print summary\n",
    "if issues:\n",
    "    print(\"Issues Identified:\")\n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "    print(\"\\nRecommended Actions:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "else:\n",
    "    print(\"✓ Dataset appears clean and consistent\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
