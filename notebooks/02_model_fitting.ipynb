{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting and Output Exploration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load data and fit the hierarchical Bayesian model\n",
    "2. Examine convergence diagnostics\n",
    "3. Extract and visualize player/team rankings\n",
    "4. Generate match predictions\n",
    "5. Perform posterior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "from rugby_ranking.model.data import MatchDataset\n",
    "from rugby_ranking.model.core import RugbyModel, ModelConfig\n",
    "from rugby_ranking.model.inference import ModelFitter, InferenceConfig\n",
    "from rugby_ranking.model.predictions import MatchPredictor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "az.style.use('arviz-darkgrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../../Rugby-Data\")  # Adjust path as needed\n",
    "\n",
    "dataset = MatchDataset(DATA_DIR)\n",
    "dataset.load_json_files()\n",
    "\n",
    "df = dataset.to_dataframe(played_only=True)\n",
    "\n",
    "# Filter to valid positions (1-23)\n",
    "df = df[df['position'].between(1, 23)].copy()\n",
    "\n",
    "print(f\"Observations: {len(df):,}\")\n",
    "print(f\"Players: {df['player_name'].nunique():,}\")\n",
    "print(f\"Teams: {df['team'].nunique()}\")\n",
    "print(f\"Matches: {df['match_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and Fit Model\n",
    "\n",
    "We'll start with a single score type (tries) to validate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model\n",
    "config = ModelConfig(\n",
    "    score_types=(\"tries\",),  # Start with tries only\n",
    "    player_effect_sd=0.5,\n",
    "    team_effect_sd=0.3,\n",
    "    position_effect_sd=0.5,\n",
    ")\n",
    "\n",
    "model = RugbyModel(config)\n",
    "pymc_model = model.build(df, score_type=\"tries\")\n",
    "\n",
    "print(\"Model built successfully\")\n",
    "print(f\"  Players: {len(model._player_ids)}\")\n",
    "print(f\"  Team-seasons: {len(model._team_season_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit using Variational Inference (fast)\n",
    "inference_config = InferenceConfig(\n",
    "    vi_n_iterations=30000,  # Reduce for faster iteration\n",
    "    vi_method=\"advi\",\n",
    ")\n",
    "\n",
    "fitter = ModelFitter(model, inference_config)\n",
    "\n",
    "print(\"Fitting model with VI...\")\n",
    "trace = fitter.fit_vi(n_samples=2000)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Full MCMC (slower but more accurate)\n",
    "\n",
    "Uncomment to run full MCMC sampling. This takes longer but provides better uncertainty estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full MCMC (uncomment to run)\n",
    "# inference_config = InferenceConfig(\n",
    "#     mcmc_draws=1000,\n",
    "#     mcmc_tune=500,\n",
    "#     mcmc_chains=4,\n",
    "#     mcmc_cores=4,\n",
    "# )\n",
    "# fitter = ModelFitter(model, inference_config)\n",
    "# trace = fitter.fit_mcmc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "diag = fitter.diagnostics()\n",
    "print(\"Convergence Diagnostics:\")\n",
    "print(f\"  R-hat max: {diag['r_hat_max']:.4f} (should be < 1.01)\")\n",
    "print(f\"  R-hat mean: {diag['r_hat_mean']:.4f}\")\n",
    "print(f\"  ESS bulk min: {diag['ess_bulk_min']:.0f} (should be > 400)\")\n",
    "print(f\"  ESS tail min: {diag['ess_tail_min']:.0f}\")\n",
    "print(f\"  Method: {diag['fit_method']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArviZ summary for key parameters\n",
    "summary = az.summary(trace, var_names=['alpha', 'eta_home', 'sigma_player', 'sigma_team'])\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior distributions for global parameters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "az.plot_posterior(trace, var_names=['alpha'], ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Baseline Log-Rate (α)')\n",
    "\n",
    "az.plot_posterior(trace, var_names=['eta_home'], ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Home Advantage (η)')\n",
    "\n",
    "az.plot_posterior(trace, var_names=['sigma_player'], ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Player Effect SD (σ_player)')\n",
    "\n",
    "az.plot_posterior(trace, var_names=['sigma_team'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Team Effect SD (σ_team)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Player Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top try-scorers by estimated ability\n",
    "player_rankings = model.get_player_rankings(top_n=30)\n",
    "display(player_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top players with uncertainty\n",
    "top_n = 20\n",
    "rankings = model.get_player_rankings(top_n=top_n)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "y_pos = np.arange(top_n)\n",
    "ax.barh(y_pos, rankings['effect_mean'], xerr=rankings['effect_std'] * 1.96, \n",
    "        align='center', alpha=0.7, capsize=3)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(rankings['player'])\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Player Effect (log-rate)')\n",
    "ax.set_title(f'Top {top_n} Try Scorers (with 95% CI)')\n",
    "ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player effect distribution\n",
    "beta = trace.posterior['beta_player'].values.flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(beta, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "ax.set_xlabel('Player Effect')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Distribution of Player Effects')\n",
    "ax.axvline(x=0, color='red', linestyle='--', label='Average')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Player effect range: [{beta.min():.2f}, {beta.max():.2f}]\")\n",
    "print(f\"Player effect std: {beta.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Team Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most recent season\n",
    "seasons = sorted(model._season_ids.keys())\n",
    "current_season = seasons[-1] if seasons else None\n",
    "print(f\"Current season: {current_season}\")\n",
    "\n",
    "# Team rankings for current season\n",
    "team_rankings = model.get_team_rankings(season=current_season, top_n=20)\n",
    "display(team_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize team rankings\n",
    "if len(team_rankings) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    y_pos = np.arange(len(team_rankings))\n",
    "    colors = ['green' if x > 0 else 'red' for x in team_rankings['effect_mean']]\n",
    "    \n",
    "    ax.barh(y_pos, team_rankings['effect_mean'], xerr=team_rankings['effect_std'] * 1.96,\n",
    "            align='center', alpha=0.7, capsize=3, color=colors)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(team_rankings['team'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Team Effect (log-rate)')\n",
    "    ax.set_title(f'Team Rankings - {current_season} (with 95% CI)')\n",
    "    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Position Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract position effects\n",
    "theta = trace.posterior['theta_position'].values\n",
    "theta_mean = theta.mean(axis=(0, 1))\n",
    "theta_std = theta.std(axis=(0, 1))\n",
    "\n",
    "positions = {\n",
    "    1: 'LH Prop', 2: 'Hooker', 3: 'TH Prop',\n",
    "    4: 'Lock', 5: 'Lock', 6: 'Blindside', 7: 'Openside', 8: 'No.8',\n",
    "    9: 'Scrum-half', 10: 'Fly-half', 11: 'Left Wing',\n",
    "    12: 'Inside Ctr', 13: 'Outside Ctr', 14: 'Right Wing', 15: 'Fullback',\n",
    "    16: 'Rep HK', 17: 'Rep LH', 18: 'Rep TH', 19: 'Rep LK', 20: 'Rep BR',\n",
    "    21: 'Rep SH', 22: 'Rep FH', 23: 'Rep BK'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "x_pos = np.arange(23)\n",
    "colors = ['#1f77b4' if i < 8 else '#2ca02c' if i < 15 else '#7f7f7f' for i in range(23)]\n",
    "\n",
    "ax.bar(x_pos, theta_mean, yerr=theta_std * 1.96, capsize=3, alpha=0.7, color=colors)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([positions.get(i+1, str(i+1)) for i in range(23)], rotation=45, ha='right')\n",
    "ax.set_ylabel('Position Effect (log-rate)')\n",
    "ax.set_title('Try-Scoring Rate by Position (with 95% CI)')\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#1f77b4', label='Forwards'),\n",
    "    Patch(facecolor='#2ca02c', label='Backs'),\n",
    "    Patch(facecolor='#7f7f7f', label='Replacements')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Match Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor\n",
    "predictor = MatchPredictor(model, trace)\n",
    "\n",
    "# Example prediction (teams only)\n",
    "# Find some teams that exist in the current season\n",
    "current_teams = [ts[0] for ts in model._team_season_ids.keys() if ts[1] == current_season]\n",
    "print(f\"Teams in {current_season}: {current_teams[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a match (adjust team names as needed)\n",
    "if len(current_teams) >= 2:\n",
    "    home_team = current_teams[0]\n",
    "    away_team = current_teams[1]\n",
    "    \n",
    "    try:\n",
    "        prediction = predictor.predict_teams_only(\n",
    "            home_team=home_team,\n",
    "            away_team=away_team,\n",
    "            season=current_season,\n",
    "            n_samples=2000\n",
    "        )\n",
    "        \n",
    "        print(prediction.summary())\n",
    "        print()\n",
    "        print(f\"Detailed breakdown:\")\n",
    "        print(f\"  Home ({home_team}): {prediction.home.mean:.1f} ± {prediction.home.std:.1f}\")\n",
    "        print(f\"  Away ({away_team}): {prediction.away.mean:.1f} ± {prediction.away.std:.1f}\")\n",
    "        print(f\"  90% CI Home: [{prediction.home.ci_lower:.0f}, {prediction.home.ci_upper:.0f}]\")\n",
    "        print(f\"  90% CI Away: [{prediction.away.ci_lower:.0f}, {prediction.away.ci_upper:.0f}]\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not predict: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions\n",
    "if 'prediction' in dir() and prediction is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Score distributions\n",
    "    axes[0].hist(prediction.home.samples, bins=30, alpha=0.6, label=home_team, density=True)\n",
    "    axes[0].hist(prediction.away.samples, bins=30, alpha=0.6, label=away_team, density=True)\n",
    "    axes[0].set_xlabel('Predicted Score')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].set_title('Score Distributions')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Margin distribution\n",
    "    margin = prediction.home.samples - prediction.away.samples\n",
    "    axes[1].hist(margin, bins=40, alpha=0.7, color='purple', density=True)\n",
    "    axes[1].axvline(x=0, color='red', linestyle='--', label='Draw')\n",
    "    axes[1].axvline(x=margin.mean(), color='green', linestyle='-', label=f'Mean: {margin.mean():.1f}')\n",
    "    axes[1].set_xlabel('Margin (Home - Away)')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].set_title('Predicted Margin')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Posterior Predictive Checks\n",
    "\n",
    "Compare model predictions to observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare observed vs predicted try rates by position\n",
    "observed_rates = df.groupby('position').agg({\n",
    "    'tries': 'sum',\n",
    "    'minutes_played': 'sum'\n",
    "})\n",
    "observed_rates['rate_per_80'] = observed_rates['tries'] / observed_rates['minutes_played'] * 80\n",
    "\n",
    "# Get model predictions for each position\n",
    "alpha_mean = trace.posterior['alpha'].values.mean()\n",
    "theta_mean = trace.posterior['theta_position'].values.mean(axis=(0, 1))\n",
    "\n",
    "predicted_rate = np.exp(alpha_mean + theta_mean)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "positions_list = list(range(1, 24))\n",
    "x = np.arange(len(positions_list))\n",
    "width = 0.35\n",
    "\n",
    "obs_rates = [observed_rates.loc[p, 'rate_per_80'] if p in observed_rates.index else 0 \n",
    "             for p in positions_list]\n",
    "pred_rates = predicted_rate[:23]\n",
    "\n",
    "ax.bar(x - width/2, obs_rates, width, label='Observed', alpha=0.7)\n",
    "ax.bar(x + width/2, pred_rates, width, label='Predicted', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Position')\n",
    "ax.set_ylabel('Tries per 80 minutes')\n",
    "ax.set_title('Observed vs Predicted Try Rates by Position')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([positions.get(p, str(p)) for p in positions_list], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Checkpoint\n",
    "\n",
    "Save the fitted model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "checkpoint_path = fitter.save(\"tries_model_v1\")\n",
    "print(f\"Saved to: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load later:\n",
    "# fitter = ModelFitter.load(\"tries_model_v1\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exploring Individual Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a specific player's history and model estimate\n",
    "def analyze_player(player_name):\n",
    "    \"\"\"Analyze a specific player's career and model estimate.\"\"\"\n",
    "    if player_name not in model._player_ids:\n",
    "        print(f\"Player '{player_name}' not found in model\")\n",
    "        return\n",
    "    \n",
    "    player_idx = model._player_ids[player_name]\n",
    "    \n",
    "    # Get player effect from posterior\n",
    "    beta = trace.posterior['beta_player'].values[:, :, player_idx]\n",
    "    \n",
    "    # Get player's match history\n",
    "    player_df = df[df['player_name'] == player_name].copy()\n",
    "    \n",
    "    print(f\"=== {player_name} ===\")\n",
    "    print(f\"Matches: {len(player_df)}\")\n",
    "    print(f\"Total tries: {player_df['tries'].sum()}\")\n",
    "    print(f\"Try rate: {player_df['tries'].sum() / player_df['minutes_played'].sum() * 80:.2f} per 80 min\")\n",
    "    print(f\"Teams: {player_df['team'].unique().tolist()}\")\n",
    "    print(f\"Seasons: {sorted(player_df['season'].unique().tolist())}\")\n",
    "    print()\n",
    "    print(f\"Model estimate:\")\n",
    "    print(f\"  Effect mean: {beta.mean():.3f}\")\n",
    "    print(f\"  Effect std: {beta.std():.3f}\")\n",
    "    print(f\"  95% CI: [{np.percentile(beta, 2.5):.3f}, {np.percentile(beta, 97.5):.3f}]\")\n",
    "    \n",
    "    # Plot posterior\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.hist(beta.flatten(), bins=50, density=True, alpha=0.7)\n",
    "    ax.axvline(x=0, color='gray', linestyle='--', label='League average')\n",
    "    ax.axvline(x=beta.mean(), color='red', linestyle='-', label=f'Mean: {beta.mean():.3f}')\n",
    "    ax.set_xlabel('Player Effect')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'Posterior Distribution: {player_name}')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example: analyze top player\n",
    "top_player = player_rankings.iloc[0]['player']\n",
    "analyze_player(top_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a specific player\n",
    "def search_players(query):\n",
    "    \"\"\"Search for players by name.\"\"\"\n",
    "    matches = [p for p in model._player_ids.keys() if query.lower() in p.lower()]\n",
    "    return sorted(matches)[:20]\n",
    "\n",
    "# Example search\n",
    "print(\"Players matching 'van der':\", search_players(\"van der\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
